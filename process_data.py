"""
=============================================================================
è‚¡ç¥¨æ•°æ®å¤„ç†å·¥å…· - ä½¿ç”¨è¯´æ˜Ž
=============================================================================

æœ¬è„šæœ¬ç”¨äºŽå¤„ç†åŽŸå§‹è‚¡ç¥¨æ•°æ®ï¼Œå°†å…¶è½¬æ¢ä¸ºé€‚åˆå›žæµ‹ç³»ç»Ÿä½¿ç”¨çš„æ ¼å¼ã€‚

ðŸŽ¯ ä¸»è¦åŠŸèƒ½ï¼š
-----------
1. è¿‡æ»¤å¸‚åœºäº¤æ˜“æ—¶é—´æ•°æ®ï¼ˆ9:30 AM - 4:00 PMï¼‰
2. è®¡ç®—æ¯æ—¥å¼€ç›˜ä»·å’Œæ”¶ç›˜ä»·
3. æ·»åŠ MACDæŠ€æœ¯æŒ‡æ ‡
4. ç”Ÿæˆé€‚åˆå›žæµ‹ç³»ç»Ÿä½¿ç”¨çš„CSVæ–‡ä»¶

ðŸ“Š æ•°æ®è½¬æ¢ï¼š
-----------
è¾“å…¥æ ¼å¼ï¼ˆåŽŸå§‹CSVï¼‰ï¼š
    DateTime,Open,High,Low,Close,Volume
    2000-01-03 09:31:00,192.375,192.375,191.5,192.0,376100

è¾“å‡ºæ ¼å¼ï¼ˆå¤„ç†åŽCSVï¼‰ï¼š
    DateTime,Open,High,Low,Close,Volume,Year,DayOpen,DayClose,Date,Time,EMA_fast,EMA_slow,MACD,MACD_signal,MACD_histogram

ðŸš€ ä½¿ç”¨æ–¹æ³•ï¼š
-----------
æ–¹æ³•1ï¼šå‘½ä»¤è¡Œä½¿ç”¨
    python process_data.py qqq.csv
    # è¾“å‡ºï¼šqqq_market_hours_with_indicators.csv

æ–¹æ³•2ï¼šæŒ‡å®šè¾“å‡ºæ–‡ä»¶
    python process_data.py qqq.csv --output my_output.csv

æ–¹æ³•3ï¼šè‡ªå®šä¹‰MACDå‚æ•°
    python process_data.py qqq.csv --fast 12 --slow 26 --signal 9

ðŸ“‹ å‘½ä»¤è¡Œå‚æ•°ï¼š
-------------
- input_file: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
- --output, -o: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰
- --fast: MACDå¿«é€ŸEMAå‘¨æœŸï¼ˆé»˜è®¤ï¼š12ï¼‰
- --slow: MACDæ…¢é€ŸEMAå‘¨æœŸï¼ˆé»˜è®¤ï¼š26ï¼‰
- --signal: MACDä¿¡å·çº¿EMAå‘¨æœŸï¼ˆé»˜è®¤ï¼š9ï¼‰

ðŸ’¡ ä½¿ç”¨ç¤ºä¾‹ï¼š
-----------
# åŸºæœ¬ç”¨æ³• - å¤„ç†QQQæ•°æ®
python process_data.py qqq.csv

# å¤„ç†SPYæ•°æ®å¹¶æŒ‡å®šè¾“å‡ºæ–‡ä»¶
python process_data.py spy.csv --output spy_processed.csv

# ä½¿ç”¨è‡ªå®šä¹‰MACDå‚æ•°
python process_data.py qqq.csv --fast 10 --slow 20 --signal 5

ðŸ“ æ–‡ä»¶è¯´æ˜Žï¼š
-----------
- qqq.csv: åŽŸå§‹QQQæ•°æ®æ–‡ä»¶ï¼ˆåŒ…å«ç›˜å‰ç›˜åŽæ•°æ®ï¼‰
- qqq_market_hours_with_indicators.csv: å¤„ç†åŽçš„æ–‡ä»¶ï¼ˆä»…å¸‚åœºæ—¶é—´+æŒ‡æ ‡ï¼‰

âš ï¸ æ³¨æ„äº‹é¡¹ï¼š
-----------
1. è¾“å…¥æ–‡ä»¶å¿…é¡»åŒ…å«DateTime, Open, High, Low, Close, Volumeåˆ—
2. DateTimeæ ¼å¼åº”ä¸º 'YYYY-MM-DD HH:MM:SS'
3. å¤„ç†åŽçš„æ–‡ä»¶ä¼šè¿‡æ»¤æŽ‰ç›˜å‰ç›˜åŽæ•°æ®ï¼Œåªä¿ç•™9:30-16:00çš„æ•°æ®
4. å¦‚æžœæŸäº›äº¤æ˜“æ—¥ç¼ºå°‘9:30æˆ–16:00çš„æ•°æ®ç‚¹ï¼Œä¼šåœ¨å¤„ç†è¿‡ç¨‹ä¸­æ˜¾ç¤ºè­¦å‘Š

ðŸ”§ å¤„ç†æµç¨‹ï¼š
-----------
1. è¯»å–åŽŸå§‹CSVæ–‡ä»¶
2. è¿‡æ»¤å¸‚åœºäº¤æ˜“æ—¶é—´ï¼ˆ9:30 AM - 4:00 PMï¼‰
3. è®¡ç®—æ¯æ—¥å¼€ç›˜ä»·ï¼ˆ9:30 AMï¼‰å’Œæ”¶ç›˜ä»·ï¼ˆ4:00 PMï¼‰
4. æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—MACDæŒ‡æ ‡
5. ä¿å­˜å¤„ç†åŽçš„æ•°æ®åˆ°æ–°æ–‡ä»¶

=============================================================================
"""

import pandas as pd
import numpy as np
import os
import sys
import argparse
from datetime import time

def prepare_market_hours_data(df):
    """
    Process data to filter for market hours and calculate day open/close prices.
    
    Parameters:
        df (DataFrame): Input DataFrame with stock data
    
    Returns:
        DataFrame: Processed DataFrame with market hours data
    """
    # Extract date and time components if not already present
    if 'Date' not in df.columns:
        df['Date'] = df['DateTime'].dt.date
    if 'Time' not in df.columns:
        df['Time'] = df['DateTime'].dt.time

    # Filter data to include only regular market hours (9:30 AM - 4:00 PM)
    market_open = time(9, 30)
    market_close = time(16, 0)

    # Create a mask for regular market hours
    market_hours_mask = (df['Time'] >= market_open) & (df['Time'] <= market_close)
    df_market_hours = df[market_hours_mask].copy()

    print(f"Rows after filtering for market hours: {len(df_market_hours)}")

    # Group by date to find the first (9:30 AM) and last (4:00 PM) data points for each day
    # For each day, get the first row (9:30 AM opening price)
    opening_prices = df_market_hours.groupby('Date').first().reset_index()
    opening_prices = opening_prices[['Date', 'Open']].rename(columns={'Open': 'DayOpen'})

    # For each day, get the last row (4:00 PM closing price)
    closing_prices = df_market_hours.groupby('Date').last().reset_index()
    closing_prices = closing_prices[['Date', 'Close']].rename(columns={'Close': 'DayClose'})

    # Merge the opening and closing prices back to the main dataframe
    df_market_hours = pd.merge(df_market_hours, opening_prices, on='Date', how='left')
    df_market_hours = pd.merge(df_market_hours, closing_prices, on='Date', how='left')

    # Check if 'Year' column exists, if not, extract it from DateTime
    if 'Year' not in df_market_hours.columns:
        df_market_hours['Year'] = df_market_hours['DateTime'].dt.year

    # Create a new dataframe with the filtered data
    columns_to_keep = ['DateTime', 'Open', 'High', 'Low', 'Close', 'Volume', 'Year', 'DayOpen', 'DayClose', 'Date', 'Time']
    filtered_df = df_market_hours[columns_to_keep].copy()

    # Display some statistics about the filtered data
    print(f"Total number of trading days: {filtered_df['Date'].nunique()}")
    print(f"Date range: {filtered_df['DateTime'].min().date()} to {filtered_df['DateTime'].max().date()}")
    print(f"Average number of data points per day: {len(filtered_df) / filtered_df['Date'].nunique():.2f}")

    # Check if there are any days with missing 9:30 AM or 4:00 PM data points
    market_open_time = time(9, 30)
    market_close_time = time(16, 0)

    # Group by date and check if each day has data at 9:30 AM and 4:00 PM
    day_times = df_market_hours.groupby('Date')['Time'].apply(list).reset_index()
    days_missing_open = []
    days_missing_close = []

    for _, row in day_times.iterrows():
        if market_open_time not in row['Time']:
            days_missing_open.append(row['Date'])
        if market_close_time not in row['Time']:
            days_missing_close.append(row['Date'])

    print(f"Number of days missing 9:30 AM data: {len(days_missing_open)}")
    print(f"Number of days missing 4:00 PM data: {len(days_missing_close)}")

    if days_missing_open:
        print("Sample of days missing 9:30 AM data:")
        print(days_missing_open[:5])
        
    if days_missing_close:
        print("Sample of days missing 4:00 PM data:")
        print(days_missing_close[:5])
        
    return filtered_df

def calculate_macd(df, fast_period=12, slow_period=26, signal_period=9):
    """
    è®¡ç®—MACDæŒ‡æ ‡
    
    å‚æ•°:
        df: åŒ…å«ä»·æ ¼æ•°æ®çš„DataFrame
        fast_period: å¿«é€ŸEMAå‘¨æœŸ
        slow_period: æ…¢é€ŸEMAå‘¨æœŸ
        signal_period: ä¿¡å·çº¿EMAå‘¨æœŸ
        
    è¿”å›ž:
        æ·»åŠ äº†MACDæŒ‡æ ‡çš„DataFrame
    """
    # å¤åˆ¶DataFrameä»¥é¿å…ä¿®æ”¹åŽŸå§‹æ•°æ®
    df_copy = df.copy()
    
    # è®¡ç®—å¿«é€Ÿå’Œæ…¢é€ŸEMA
    df_copy['EMA_fast'] = df_copy['Close'].ewm(span=fast_period, adjust=False).mean()
    df_copy['EMA_slow'] = df_copy['Close'].ewm(span=slow_period, adjust=False).mean()
    
    # è®¡ç®—MACDçº¿
    df_copy['MACD'] = df_copy['EMA_fast'] - df_copy['EMA_slow']
    
    # è®¡ç®—ä¿¡å·çº¿
    df_copy['MACD_signal'] = df_copy['MACD'].ewm(span=signal_period, adjust=False).mean()
    
    # è®¡ç®—æŸ±çŠ¶å›¾
    df_copy['MACD_histogram'] = df_copy['MACD'] - df_copy['MACD_signal']
    
    return df_copy

def process_data(input_file, output_file=None, fast_period=12, slow_period=26, signal_period=9):
    """
    å¤„ç†CSVæ–‡ä»¶ï¼Œè¿‡æ»¤å¸‚åœºäº¤æ˜“æ—¶é—´å¹¶æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
    
    å‚æ•°:
        input_file: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æžœä¸ºNoneï¼Œå°†åŸºäºŽè¾“å…¥æ–‡ä»¶åç”Ÿæˆï¼‰
        fast_period: MACDå¿«é€ŸEMAå‘¨æœŸ
        slow_period: MACDæ…¢é€ŸEMAå‘¨æœŸ
        signal_period: MACDä¿¡å·çº¿EMAå‘¨æœŸ
        
    è¿”å›ž:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # å¦‚æžœæœªæŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œåˆ™åŸºäºŽè¾“å…¥æ–‡ä»¶åç”Ÿæˆ
    if output_file is None:
        base_name = os.path.basename(input_file)
        ticker = os.path.splitext(base_name)[0]
        output_dir = os.path.dirname(input_file)
        output_file = os.path.join(output_dir, f"{ticker}_market_hours_with_indicators.csv")
    
    print(f"è¯»å–æ•°æ®æ–‡ä»¶: {input_file}")
    df = pd.read_csv(input_file)

    # ç¡®ä¿DateTimeåˆ—æ˜¯datetimeæ ¼å¼
    df['DateTime'] = pd.to_datetime(df['DateTime'])
    
    # æ˜¾ç¤ºåŽŸå§‹æ•°æ®æ ·æœ¬
    print("åŽŸå§‹æ•°æ®æ ·æœ¬:")
    print(df.head())
    print(f"åŽŸå§‹æ•°æ®æ€»è¡Œæ•°: {len(df)}")
    
    # æ­¥éª¤1: è¿‡æ»¤å¸‚åœºäº¤æ˜“æ—¶é—´æ•°æ®
    print("\næ­¥éª¤1: è¿‡æ»¤å¸‚åœºäº¤æ˜“æ—¶é—´æ•°æ®...")
    market_hours_df = prepare_market_hours_data(df)
    
    # æ­¥éª¤2: è®¡ç®—MACDæŒ‡æ ‡
    print("\næ­¥éª¤2: è®¡ç®—MACDæŒ‡æ ‡...")
    # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æŽ’åº
    market_hours_df.sort_values('DateTime', inplace=True)
    
    # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—MACD
    grouped = market_hours_df.groupby('Date')
    result_dfs = []
    
    for date, group in grouped:
        # è®¡ç®—å½“å¤©çš„MACD
        group_with_macd = calculate_macd(
            group, 
            fast_period=fast_period, 
            slow_period=slow_period, 
            signal_period=signal_period
        )
        result_dfs.append(group_with_macd)
    
    # åˆå¹¶æ‰€æœ‰æ—¥æœŸçš„ç»“æžœ
    result_df = pd.concat(result_dfs)
    
    # ä¿å­˜ç»“æžœ
    result_df.to_csv(output_file, index=False)
    print(f"\nå¤„ç†å®Œæˆ! å¸¦æœ‰å¸‚åœºäº¤æ˜“æ—¶é—´å’ŒMACDæŒ‡æ ‡çš„æ•°æ®å·²ä¿å­˜è‡³: {output_file}")
    
    return output_file

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='å¤„ç†è‚¡ç¥¨æ•°æ®ï¼šè¿‡æ»¤å¸‚åœºäº¤æ˜“æ—¶é—´å¹¶æ·»åŠ æŠ€æœ¯æŒ‡æ ‡')
    parser.add_argument('input_file', help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--fast', type=int, default=12, help='MACDå¿«é€ŸEMAå‘¨æœŸï¼ˆé»˜è®¤ï¼š12ï¼‰')
    parser.add_argument('--slow', type=int, default=26, help='MACDæ…¢é€ŸEMAå‘¨æœŸï¼ˆé»˜è®¤ï¼š26ï¼‰')
    parser.add_argument('--signal', type=int, default=9, help='MACDä¿¡å·çº¿EMAå‘¨æœŸï¼ˆé»˜è®¤ï¼š9ï¼‰')
    
    args = parser.parse_args()
    
    process_data(
        args.input_file, 
        args.output, 
        fast_period=args.fast, 
        slow_period=args.slow, 
        signal_period=args.signal
    )
